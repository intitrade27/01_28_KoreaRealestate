# ë„¤ì´ë²„/ì¹´ì¹´ì˜¤ ë¶€ë™ì‚° ë°ì´í„° ì—°ë™ ê¸°ìˆ  ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìˆ˜ì§‘](#ë„¤ì´ë²„-ë¶€ë™ì‚°-ë°ì´í„°-ìˆ˜ì§‘)
3. [ì¹´ì¹´ì˜¤ ë¶€ë™ì‚° ë°ì´í„° ìˆ˜ì§‘](#ì¹´ì¹´ì˜¤-ë¶€ë™ì‚°-ë°ì´í„°-ìˆ˜ì§‘)
4. [ëŒ€ì•ˆ ì†”ë£¨ì…˜](#ëŒ€ì•ˆ-ì†”ë£¨ì…˜)
5. [ë²•ì  ê³ ë ¤ì‚¬í•­](#ë²•ì -ê³ ë ¤ì‚¬í•­)

---

## ê°œìš”

ë„¤ì´ë²„ì™€ ì¹´ì¹´ì˜¤ëŠ” **ê³µì‹ ë¶€ë™ì‚° ë§¤ë¬¼ APIë¥¼ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**. ë”°ë¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤:

### ê°€ëŠ¥í•œ ì ‘ê·¼ ë°©ë²•
1. **ì›¹ ìŠ¤í¬ë˜í•‘** (Selenium/Playwright)
2. **ëª¨ë°”ì¼ API ì—­ë¶„ì„** (ë¹„ê³µì‹)
3. **ê³µì‹ ëŒ€ì•ˆ í”Œë«í¼** (ì§ë°©, ë‹¤ë°© ë“±)

---

## ë„¤ì´ë²„ ë¶€ë™ì‚° ë°ì´í„° ìˆ˜ì§‘

### 1. Seleniumì„ í™œìš©í•œ ì›¹ ìŠ¤í¬ë˜í•‘ (ê¶Œì¥)

#### ì„¤ì¹˜
```bash
pip install selenium webdriver-manager
```

#### êµ¬í˜„ ì˜ˆì‹œ
```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time

def fetch_naver_land_listings(region_code: str, trade_type: str = "A1") -> pd.DataFrame:
    """
    ë„¤ì´ë²„ ë¶€ë™ì‚° ë§¤ë¬¼ í¬ë¡¤ë§
    
    Args:
        region_code: ì§€ì—­ ì½”ë“œ (ì˜ˆ: "1168000000" - ê°•ë‚¨êµ¬)
        trade_type: ê±°ë˜ ìœ í˜• (A1: ë§¤ë§¤, B1: ì „ì„¸, B2: ì›”ì„¸)
    
    Returns:
        pd.DataFrame: ë§¤ë¬¼ ì •ë³´
    """
    
    # Chrome ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    
    # ë“œë¼ì´ë²„ ì´ˆê¸°í™”
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=chrome_options
    )
    
    try:
        # ë„¤ì´ë²„ ë¶€ë™ì‚° URL
        url = f"https://new.land.naver.com/complexes?ms={region_code}&a={trade_type}&e=RETAIL"
        driver.get(url)
        time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        
        # ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ë°ì´í„° ë¡œë“œ
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
        
        # ë§¤ë¬¼ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        listings = []
        
        # ì•„íŒŒíŠ¸ ë‹¨ì§€ ìš”ì†Œ ì°¾ê¸°
        complex_items = driver.find_elements(By.CSS_SELECTOR, ".item_complex")
        
        for item in complex_items:
            try:
                # ë‹¨ì§€ëª…
                name = item.find_element(By.CSS_SELECTOR, ".text").text
                
                # ê°€ê²© ì •ë³´
                price_elem = item.find_element(By.CSS_SELECTOR, ".price")
                price = price_elem.text
                
                # ë©´ì  ì •ë³´
                area_elem = item.find_element(By.CSS_SELECTOR, ".spec")
                area = area_elem.text
                
                listings.append({
                    'name': name,
                    'price': price,
                    'area': area,
                    'source': 'naver'
                })
                
            except Exception as e:
                continue
        
        return pd.DataFrame(listings)
    
    finally:
        driver.quit()

# ì‚¬ìš© ì˜ˆì‹œ
df = fetch_naver_land_listings("1168000000")  # ê°•ë‚¨êµ¬
print(df.head())
```

### 2. Playwrightë¥¼ í™œìš©í•œ ê³ ê¸‰ ìŠ¤í¬ë˜í•‘

```bash
pip install playwright
playwright install chromium
```

```python
from playwright.sync_api import sync_playwright
import pandas as pd

def fetch_with_playwright(region: str) -> pd.DataFrame:
    """Playwrightë¥¼ ì‚¬ìš©í•œ ë„¤ì´ë²„ ë¶€ë™ì‚° í¬ë¡¤ë§"""
    
    with sync_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹¤í–‰
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        )
        page = context.new_page()
        
        # ë„¤ì´ë²„ ë¶€ë™ì‚° ì ‘ì†
        page.goto(f'https://new.land.naver.com/complexes?ms={region}')
        page.wait_for_load_state('networkidle')
        
        # ë°ì´í„° ì¶”ì¶œ
        listings = page.query_selector_all('.item_complex')
        
        data = []
        for listing in listings:
            name = listing.query_selector('.text').inner_text()
            price = listing.query_selector('.price').inner_text()
            
            data.append({
                'name': name,
                'price': price
            })
        
        browser.close()
        
        return pd.DataFrame(data)
```

### 3. ë„¤ì´ë²„ ëª¨ë°”ì¼ API ì—­ë¶„ì„ (ê³ ê¸‰)

ë„¤ì´ë²„ ë¶€ë™ì‚° ëª¨ë°”ì¼ ì•±ì€ JSON APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import requests
import json

def fetch_naver_api(lat: float, lon: float, zoom: int = 15) -> dict:
    """
    ë„¤ì´ë²„ ë¶€ë™ì‚° ë¹„ê³µì‹ API í˜¸ì¶œ
    
    ì£¼ì˜: ì´ ë°©ë²•ì€ ë„¤ì´ë²„ì˜ ì„œë¹„ìŠ¤ ì•½ê´€ì„ ìœ„ë°˜í•  ìˆ˜ ìˆìœ¼ë©°,
    API êµ¬ì¡°ê°€ ë³€ê²½ë˜ë©´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    
    # ë„¤ì´ë²„ ë¶€ë™ì‚° ëª¨ë°”ì¼ API ì—”ë“œí¬ì¸íŠ¸
    url = "https://m.land.naver.com/cluster/clusterList"
    
    # ìš”ì²­ íŒŒë¼ë¯¸í„°
    params = {
        'cortarNo': '1168000000',  # ì§€ì—­ ì½”ë“œ
        'view': 'atcl',
        'rletTpCd': 'APT',  # ì•„íŒŒíŠ¸
        'tradTpCd': 'A1',   # ë§¤ë§¤
        'z': zoom,
        'lat': lat,
        'lon': lon,
    }
    
    # í—¤ë” ì„¤ì •
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)',
        'Referer': 'https://m.land.naver.com/',
        'Accept': 'application/json'
    }
    
    try:
        response = requests.get(url, params=params, headers=headers)
        return response.json()
    except Exception as e:
        print(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {}

# ì‚¬ìš© ì˜ˆì‹œ
data = fetch_naver_api(37.5172, 127.0473)  # ê°•ë‚¨ì—­ ì¢Œí‘œ
print(json.dumps(data, indent=2, ensure_ascii=False))
```

---

## ì¹´ì¹´ì˜¤ ë¶€ë™ì‚° ë°ì´í„° ìˆ˜ì§‘

### 1. ì¹´ì¹´ì˜¤ ì§€ë„ API í™œìš© (ê³µì‹)

ì¹´ì¹´ì˜¤ëŠ” ì§ì ‘ì ì¸ ë§¤ë¬¼ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šì§€ë§Œ, ì£¼ë³€ ë¶€ë™ì‚° ì¤‘ê°œì—…ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import requests
import os

KAKAO_REST_KEY = os.getenv("KAKAO_REST_KEY")

def search_real_estate_agencies(lat: float, lon: float, radius: int = 1000):
    """ì¹´ì¹´ì˜¤ ì§€ë„ APIë¡œ ì£¼ë³€ ë¶€ë™ì‚° ì¤‘ê°œì—…ì†Œ ê²€ìƒ‰"""
    
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    
    headers = {
        "Authorization": f"KakaoAK {KAKAO_REST_KEY}"
    }
    
    params = {
        "query": "ë¶€ë™ì‚°",
        "x": lon,
        "y": lat,
        "radius": radius,
        "size": 15,
        "sort": "distance"
    }
    
    response = requests.get(url, headers=headers, params=params)
    data = response.json()
    
    agencies = []
    for doc in data.get('documents', []):
        agencies.append({
            'name': doc['place_name'],
            'address': doc['address_name'],
            'phone': doc.get('phone', ''),
            'distance': doc['distance']
        })
    
    return agencies

# ì‚¬ìš© ì˜ˆì‹œ
agencies = search_real_estate_agencies(37.5172, 127.0473)
for agency in agencies:
    print(f"{agency['name']} - {agency['phone']}")
```

### 2. ì¹´ì¹´ì˜¤ë§µ ìŠ¤í¬ë˜í•‘

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time

def scrape_kakao_map(keyword: str, region: str):
    """ì¹´ì¹´ì˜¤ë§µì—ì„œ ë¶€ë™ì‚° ì •ë³´ ìŠ¤í¬ë˜í•‘"""
    
    driver = webdriver.Chrome()
    
    try:
        # ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰
        search_query = f"{region} {keyword}"
        url = f"https://map.kakao.com/?q={search_query}"
        driver.get(url)
        time.sleep(3)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
        results = driver.find_elements(By.CSS_SELECTOR, ".placelist > .PlaceItem")
        
        places = []
        for result in results:
            name = result.find_element(By.CSS_SELECTOR, ".head_item .tit_name").text
            address = result.find_element(By.CSS_SELECTOR, ".info_item .addr").text
            
            places.append({
                'name': name,
                'address': address
            })
        
        return places
    
    finally:
        driver.quit()
```

---

## ëŒ€ì•ˆ ì†”ë£¨ì…˜

### 1. ê³µê³µ API í™œìš© (ì¶”ì²œ)

ë„¤ì´ë²„/ì¹´ì¹´ì˜¤ ëŒ€ì‹  ê³µê³µë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „í•˜ê³  í•©ë²•ì ì…ë‹ˆë‹¤:

```python
# ì´ë¯¸ êµ¬í˜„ëœ êµ­í† ë¶€ API
def fetch_molit_data(lawd_cd: str, deal_ymd: str):
    """êµ­í† êµí†µë¶€ ì‹¤ê±°ë˜ê°€ API (ê³µì‹)"""
    url = "https://apis.data.go.kr/1613000/RTMSDataSvcAptTrade/getRTMSDataSvcAptTrade"
    # ... (ê¸°ì¡´ ì½”ë“œ)
```

### 2. ì§ë°© API (ë¹„ê³µì‹)

ì§ë°©ì€ ë¹„ê³µì‹ì ìœ¼ë¡œ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```python
def fetch_zigbang_items(lat: float, lon: float):
    """ì§ë°© ë§¤ë¬¼ ê²€ìƒ‰ (ë¹„ê³µì‹ API)"""
    
    # 1ë‹¨ê³„: ì§€ì—­ ID ì¡°íšŒ
    geohash_url = "https://apis.zigbang.com/v2/items/geohash"
    params = {
        'lat': lat,
        'lng': lon,
        'level': 1
    }
    
    response = requests.get(geohash_url, params=params)
    geohash_data = response.json()
    
    # 2ë‹¨ê³„: ë§¤ë¬¼ ëª©ë¡ ì¡°íšŒ
    items = []
    for gh in geohash_data:
        item_url = f"https://apis.zigbang.com/v2/items?geohash={gh['geohash']}"
        item_response = requests.get(item_url)
        items.extend(item_response.json())
    
    return items

# ì‚¬ìš© ì˜ˆì‹œ
items = fetch_zigbang_items(37.5172, 127.0473)
for item in items[:5]:
    print(f"{item.get('title')} - {item.get('sales_price')}ë§Œì›")
```

### 3. ë‹¤ë°© API (ë¹„ê³µì‹)

```python
def fetch_dabang_rooms(bbox: tuple):
    """
    ë‹¤ë°© ì›ë£¸ ë§¤ë¬¼ ê²€ìƒ‰
    
    Args:
        bbox: (ë‚¨ì„œìª½ ìœ„ë„, ë‚¨ì„œìª½ ê²½ë„, ë¶ë™ìª½ ìœ„ë„, ë¶ë™ìª½ ê²½ë„)
    """
    
    url = "https://www.dabangapp.com/api/2/room/list/bbox-point"
    
    params = {
        'api_version': '2.0.1',
        'call_type': 'web',
        'bbox': f"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]}"
    }
    
    response = requests.get(url, params=params)
    return response.json()
```

---

## ë²•ì  ê³ ë ¤ì‚¬í•­

### âš ï¸ ì£¼ì˜ì‚¬í•­

1. **robots.txt ì¤€ìˆ˜**
   ```python
   # robots.txt í™•ì¸
   import urllib.robotparser
   
   rp = urllib.robotparser.RobotFileParser()
   rp.set_url("https://land.naver.com/robots.txt")
   rp.read()
   
   can_fetch = rp.can_fetch("*", "https://land.naver.com/complexes")
   print(f"í¬ë¡¤ë§ ê°€ëŠ¥ ì—¬ë¶€: {can_fetch}")
   ```

2. **ìš”ì²­ ì œí•œ**
   ```python
   import time
   from functools import wraps
   
   def rate_limit(min_interval: float = 1.0):
       """API í˜¸ì¶œ ê°„ê²© ì œí•œ ë°ì½”ë ˆì´í„°"""
       def decorator(func):
           last_called = [0.0]
           
           @wraps(func)
           def wrapper(*args, **kwargs):
               elapsed = time.time() - last_called[0]
               if elapsed < min_interval:
                   time.sleep(min_interval - elapsed)
               result = func(*args, **kwargs)
               last_called[0] = time.time()
               return result
           
           return wrapper
       return decorator
   
   @rate_limit(2.0)  # 2ì´ˆë§ˆë‹¤ 1íšŒ í˜¸ì¶œ
   def fetch_data():
       # ... API í˜¸ì¶œ
       pass
   ```

3. **User-Agent ì„¤ì •**
   ```python
   headers = {
       'User-Agent': 'MyRealEstateApp/1.0 (contact@example.com)',
       'From': 'contact@example.com'
   }
   ```

### ê¶Œì¥ ì‚¬í•­

1. **ê³µì‹ API ìš°ì„  ì‚¬ìš©**
   - êµ­í† êµí†µë¶€ ì‹¤ê±°ë˜ê°€ API
   - í•œêµ­ë¶€ë™ì‚°ì› API
   - ì§€ìì²´ ê³µê³µë°ì´í„°

2. **ìŠ¤í¬ë˜í•‘ ì‹œ ì£¼ì˜**
   - ê³¼ë„í•œ ìš”ì²­ ìì œ
   - ìºì‹± í™œìš©
   - ì—ëŸ¬ ì²˜ë¦¬ ì² ì €íˆ

3. **ê°œì¸ì •ë³´ ë³´í˜¸**
   - ê°œì¸ ì—°ë½ì²˜ ìˆ˜ì§‘ ê¸ˆì§€
   - ë°ì´í„° ì €ì¥ ì‹œ ì•”í˜¸í™”
   - GDPR/ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜

---

## ì‹¤ë¬´ í†µí•© ì˜ˆì‹œ

### ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° í†µí•©

```python
class RealEstateDataAggregator:
    """ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ë¶€ë™ì‚° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  í†µí•©"""
    
    def __init__(self):
        self.sources = {
            'molit': self.fetch_molit,
            'zigbang': self.fetch_zigbang,
            'dabang': self.fetch_dabang
        }
    
    def fetch_all(self, region: str) -> pd.DataFrame:
        """ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = []
        
        for source_name, fetch_func in self.sources.items():
            try:
                data = fetch_func(region)
                data['source'] = source_name
                all_data.append(data)
            except Exception as e:
                print(f"{source_name} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        if all_data:
            return pd.concat(all_data, ignore_index=True)
        return pd.DataFrame()
    
    def fetch_molit(self, region: str) -> pd.DataFrame:
        # êµ­í† ë¶€ API í˜¸ì¶œ
        pass
    
    def fetch_zigbang(self, region: str) -> pd.DataFrame:
        # ì§ë°© API í˜¸ì¶œ
        pass
    
    def fetch_dabang(self, region: str) -> pd.DataFrame:
        # ë‹¤ë°© API í˜¸ì¶œ
        pass

# ì‚¬ìš©
aggregator = RealEstateDataAggregator()
df = aggregator.fetch_all("ê°•ë‚¨êµ¬")
```

---

## ê²°ë¡ 

ë„¤ì´ë²„ì™€ ì¹´ì¹´ì˜¤ì˜ ë¶€ë™ì‚° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì€ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ëŠ¥í•˜ì§€ë§Œ, ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤:

### âœ… ê¶Œì¥
- êµ­í† êµí†µë¶€ ë“± ê³µê³µ API ìš°ì„  í™œìš©
- ì§ë°©, ë‹¤ë°© ë“± ë¹„ê³µì‹ API í™œìš©
- ìŠ¤í¬ë˜í•‘ ì‹œ ë²•ì /ìœ¤ë¦¬ì  ê¸°ì¤€ ì¤€ìˆ˜

### âŒ ë¹„ê¶Œì¥
- ë¬´ë¶„ë³„í•œ ëŒ€ëŸ‰ í¬ë¡¤ë§
- robots.txt ë¬´ì‹œ
- ê°œì¸ì •ë³´ ìˆ˜ì§‘

**ìµœì„ ì˜ ë°©ë²•**: í˜„ì¬ êµ¬í˜„ëœ êµ­í† ë¶€ APIë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³ , í•„ìš”ì‹œ ì§ë°©/ë‹¤ë°© ë“±ì˜ ë³´ì™„ì  ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.
